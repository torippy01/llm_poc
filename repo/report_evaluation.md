## 目的
[前回の評価法](./report_evaluation_rules.md)では、各評価軸毎にルールを定める必要がありました．
今回の検証では、評価毎の細かいルールを作らなくても良い方法を模索します．

## 検証手法
* 以下の手法で検証してみる．
* 評価は３段階とする．

### 検証手法１
* 以下の３文章を用意
  - 質問文：人間による質問
  - 回答文：質問文に対するAIの回答
  - 正解文：人間が用意した質問文に対する正解

* プロンプト
  ```
  回答文は、質問文に対する回答が書かれています。
  正解文が、質問文に対する回答として最高の評価とするとき、回答文の評価を行いなさい。
  評価は、１から３の３段階評価とします。
  評価のフォーマットは、`評価：評価数`とします。
  また、なぜその評価を行ったかを説明しなさい。

  質問文： {sentences.input}
  回答文： {sentences.output}
  正解文： {sentences.human_answer}
  ```

### 検証手法２
* 以下の３文章を用意
  - 質問文
  - 回答文
  - 評価文：回答文としてポイントとなる事項を記載した文．人間が用意する

* プロンプト
  ```
  回答文は、質問文に対する回答が書かれています。
  評価文に基づいて、回答文の評価を行いなさい．
  評価は、１から３の３段階評価とします。
  評価のフォーマットは、`評価：評価数`とします。
  また、なぜその評価を行ったかを説明しなさい。

  質問文： {sentences.input}
  回答文： {sentences.output}
  評価文： {sentences.human_answer}
  ```
## 検証結果
* [検証手法１](./results/evaluation/diff_human_answer.md)
* [検証手法２](./results/evaluation/human_eval.md)

## まとめ
### 用語は質問文と評価文（正解文）とで合わせるとよさそう．
* Chat GPTは、同一の意味であっても質問文の用語が異なると低い評価を行う傾向がある
  - 例えば「稼働中」と「running状態」は同一のものとしてみなさない．
* 極力、評価文・正解文は、質問文に登場する用語を合わせて記述する．

### 各手法による結果の評価
* いずれの手法であっても、意図通りの評価を行うことが確認された
* 手法１（正解文）は、文意がほぼ同じであっても「冗長」という理由で低評価を食らうことがある．
* 手法２（評価文）は、冗長性を低く評価しない．

### 結論
* 手法２（評価文）をベンチマークとして取り入れるべき．
* 理由
  - 手法１（正解文）と比べて、準備のコストを抑えられる．
  - 複雑な定数的部分を書かなくてよい．
  - 手法１と比較してまともな評価をすることが多い．
