## 目的
開発用AWS環境において、ユーザーの自然言語から所望のコマンドを実行させることができるかを検証する．
当検証においては、案件やプロダクトに関するコンテキストを考慮しない．

## 検証環境
### ChatGPT
* Index用LLM: `gpt-3.5-turbo`
* 推論用LLM: `gpt-4` or `gpt-3.5-turbo`

### Lang Chain
* エージェント：`zero-shot-react-description`
* ツール
  - `command_predictor`
    * Llama Indexで実装
    * AWS CLIコマンドを取得するツール
  - `parameter_predictor_from_prompt`
    * Llama Indexで実装
    * AWS CLIコマンドの引数を取得するツール
  - `shell_tool`
    * Llama Index公式ツール
    * コマンドをターミナル上で実行するツール

### AWS
* XTERAプロジェクトのAWS環境にreadonlyのアカウントで実施

### Llama Index
* AWS CLIコマンドすべてのリファレンスを`GPTVectorStoreIndex`によってベクトル変換したインデックスを使用

## 検証手法
* 実際のAWS環境を用意し、EC2インスタンスに関して質問し、`describe-instances`コマンドを使用して所望の情報を取得できるかを検証
* 質問は、案件のコンテキストに関する情報は使用せず、具体性をもった質問で実施
  - 「〇〇案件で使っているインスタンスの外部IPアドレスを教えてください」×
  - 「インスタンスID"i-〇〇〇〇"の外部IPアドレスを教えてください」〇
* 各推論モデルの回答を分析

## 検証結果
* 検証結果（質問回答集）は別途配布（セキュリティの事由から）

## まとめと感想

### モデルが一度に入力できるトークン数による制約
- `gpt-3.5-turbo`に入力可能なトークン数が4097 token であり、コマンドの実行結果の入力でコケる事象を確認
- `gpt-4`に入力可能なトークン数が8192 token であるので、`gpt-4`においても対岸の火事ではない話．インスタンス数が6個とか10個あれば確実に落ちる．
- このため、チェインの中で多量のトークンが生成・取得された場合の対策を講じておく必要がありそう．⇒ `CharacterTextSplitter`を使用するなど．

### 対話精度
* `gpt-4`
  - `gpt-3.5-turbo`により作ったインデックスであってもちゃんと動く．
  - 総じて、回答はユーザーの要望を満たし、正確
  - コマンドの推定、クエリパラメータの推定、コマンド実行のツールを駆使していることを確認
  - 生成した実行コマンドがエラーを起こしても、修正して実行できる点を確認
  - 「インスタンスのメモリサイズは？」などの質問に対し、`describe-instances`コマンドで回答が得られなかった場合においても、インスタンスタイプ等からメモリサイズを探し当てて回答できていた．ただし、この知識はChatGPTが持っている知識であるため、古い情報を参照してくるリスクもある．

* `gpt-3.5-turbo`
  - 「〇〇するコマンドを実行して」等の指示がプロンプトに含まれる場合、「実行コマンドはコレです」のような回答をしがち．おそらくインデックスのテキストに引きずられている．
  - 実際にコマンド実行した値を返すのではなく、リファレンスのサンプルコマンドの結果をとってきたりする．インデックスのテキストに引きずられている．

* 今後の検証の方向性
  - コンテキストのインデックス化方法の検証
  - コンテキストつきの自然言語からAWS CLIのコマンドを実行させる検証
  - コマンド実行が複数ステップに渡る場合の検証